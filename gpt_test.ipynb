{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'C:/Users/wjtay/Documents/GitHub/medicalbot/gpt_models/model_save_3'\n",
    "model =  GPT2LMHeadModel.from_pretrained('C:/Users/wjtay/Documents/GitHub/medicalbot/gpt_models/model_save_3')\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50257,    27,    91, 25652,    91,    29,    72,   423, 39849,   312,\n",
      "            12,  1129,   644,   815,  1312,   466,    30,    27,    91, 41484,\n",
      "            91,    29]])\n",
      "0: <|question|>i have covid-19 what should i do?<|answer|>do not adjust your diet prior to surgery. a few times a week not sooner than one week. eat a well nourishing diet that is rich in vitamins and minerals. you will need to work with your healthcare provider to make sure you are getting enough vitamins and minerals. if you become unsure before your surgery call your healthcare provider.\n",
      "\n",
      "\n",
      "1: <|question|>i have covid-19 what should i do?<|answer|>if you are looking for medical assistance with your age and sex then yes you may well qualify. some insurance plans don't cover it and medicare plans cover it. your doctor will have to determine the plans you will need to cover. to determine what type of coverage you will qualify for he or she will ask you and you their questions.\n",
      "\n",
      "\n",
      "2: <|question|>i have covid-19 what should i do?<|answer|>do not take any antifungal medication like ibuprofen naproxen or naproxen as these can cause stomach upset and can lead to ulcers as well. your doctor can help you with the best way to treat the upset stomach.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "q1 = \"if i have trouble gaining weight because of my low appetite would a higher intake of the hormone leptin help? . i grew up always considered \"\"underweight\"\" for my age height and sex. people tell me it's just genes or i'm just a small eater but i think it's more than that. i'd like to gain more weight without being unhealthy about it. i have a low appetite and i just read an article on this website about leptin and leptin signals the body's energy-nourishment.\"\n",
    "q2 = \"i need a list of foods that i can eat and list of foods to avoid with pancreatitis\"\n",
    "q3 = \"i made a mistake and i bought 9 to 24 months formula for my newborn. can he drink it?\"\n",
    "q4 = \"i think i have bone cancer. what should i do?\"\n",
    "q5 = \"i have covid-19 what should i do?\"\n",
    "\n",
    "prompt = f\"<|startoftext|><|question|>{q5}<|answer|>\"\n",
    "\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "# generated = generated.to(device)\n",
    "\n",
    "print(generated)\n",
    "\n",
    "sample_outputs = model.generate(\n",
    "                                generated, \n",
    "                                #bos_token_id=random.randint(1,30000),\n",
    "                                do_sample=True,   \n",
    "                                top_k=50, \n",
    "                                max_length = 300,\n",
    "                                top_p=0.95, \n",
    "                                num_return_sequences=3\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "model2 = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
    "model2.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50257,  1820,  3367,   468,   751,   290, 11607, 15998,    13,   339,\n",
      "           468,   587,  7675,   319, 10010,    64,   329,   718,    10,   812,\n",
      "            13,   460,   345,  1037,   351,   465,  3463,  2994,    30]])\n",
      "0: my son has add and mild autism. he has been successfully on concerta for 6+ years. can you help with his weight loss?\n",
      "\n",
      "\n",
      "1: my son has add and mild autism. he has been successfully on concerta for 6+ years. can you help with his weight loss?\n",
      "\n",
      "\n",
      "2: my son has add and mild autism. he has been successfully on concerta for 6+ years. can you help with his weight loss?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2.eval()\n",
    "\n",
    "prompt = \"<|startoftext|>my son has add and mild autism. he has been successfully on concerta for 6+ years. can you help with his weight loss?\"\n",
    "\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "# generated = generated.to(device)\n",
    "\n",
    "print(generated)\n",
    "\n",
    "sample_outputs = model2.generate(\n",
    "                                generated, \n",
    "                                #bos_token_id=random.randint(1,30000),\n",
    "                                do_sample=True,   \n",
    "                                top_k=50, \n",
    "                                max_length = 300,\n",
    "                                top_p=0.95, \n",
    "                                num_return_sequences=3\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31412, 4)\n",
      "(31596, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# with open('filename.pickle', 'wb') as handle:\n",
    "#     pickle.dump(your_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load data (deserialize)\n",
    "# with open('training_data/MBERT_Lasse_FAISS_embeddings.pkl', 'rb') as handle:\n",
    "with open('gpu_data/MED_BERT_Lasse_Only_FAISS.pkl', 'rb') as handle:\n",
    "    unserialized_data = pickle.load(handle)\n",
    "\n",
    "training_df1 = pd.DataFrame(unserialized_data)\n",
    "print(training_df1.shape)\n",
    "\n",
    "with open('gpu_data/BERT_Lasse_Only_FAISS_embeddings.pkl', 'rb') as handle:\n",
    "    unserialized_data = pickle.load(handle)\n",
    "\n",
    "training_df2 = pd.DataFrame(unserialized_data)\n",
    "print(training_df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set1: 31008\n",
      "set2: 31105\n",
      "diff 2007\n"
     ]
    }
   ],
   "source": [
    "set1 = set()\n",
    "for idx, row in training_df1.iterrows():\n",
    "    item = tuple([row['question'], row['answer']])\n",
    "    set1.add(item)\n",
    "\n",
    "set2 = set()\n",
    "for idx, row in training_df2.iterrows():\n",
    "    item = tuple([row['question'], row['answer']])\n",
    "    set2.add(item)\n",
    "\n",
    "print(f'set1: {len(set1)}')\n",
    "print(f'set2: {len(set2)}')\n",
    "\n",
    "diff = set1.symmetric_difference(set2)\n",
    "print(f'diff {len(diff)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why am i bleeding after taking contraceptive pill?\n",
      "should i take some medicine to stop heavy bleeding after an i-pill?\n",
      "can antibiotics interfere with the depo-provera birth control shot the way they do with oral contraceptives?\n",
      "will antibiotics reduce the effect of oral contraceptive pills?\n"
     ]
    }
   ],
   "source": [
    "print(training_df.iloc[-41][\"question\"])\n",
    "print(training_df.iloc[-42][\"question\"])\n",
    "print(training_df.iloc[-43][\"question\"])\n",
    "print(training_df.iloc[-44][\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_embedding</th>\n",
       "      <th>answer_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29531</th>\n",
       "      <td>should i take some medicine to stop heavy blee...</td>\n",
       "      <td>the bleeding could be due to withdrawal effect...</td>\n",
       "      <td>[-0.4998133, 0.21075934, -0.1710357, 0.1950991...</td>\n",
       "      <td>[-0.12213257, 0.26806858, 0.04654521, 0.139121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31743</th>\n",
       "      <td>should i take some medicine to stop heavy blee...</td>\n",
       "      <td>the extra bleeding could be due to the pill. h...</td>\n",
       "      <td>[-0.4998133, 0.21075934, -0.1710357, 0.1950991...</td>\n",
       "      <td>[-0.2732135, -0.006451058, 0.19289777, 0.24179...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31746</th>\n",
       "      <td>should i take some medicine to stop heavy blee...</td>\n",
       "      <td>the extra bleeding could be due to the pill. h...</td>\n",
       "      <td>[-0.4232357, 0.27518612, -0.1223748, 0.1546501...</td>\n",
       "      <td>[-0.12213257, 0.26806858, 0.04654521, 0.139121...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "29531  should i take some medicine to stop heavy blee...   \n",
       "31743  should i take some medicine to stop heavy blee...   \n",
       "31746  should i take some medicine to stop heavy blee...   \n",
       "\n",
       "                                                  answer  \\\n",
       "29531  the bleeding could be due to withdrawal effect...   \n",
       "31743  the extra bleeding could be due to the pill. h...   \n",
       "31746  the extra bleeding could be due to the pill. h...   \n",
       "\n",
       "                                      question_embedding  \\\n",
       "29531  [-0.4998133, 0.21075934, -0.1710357, 0.1950991...   \n",
       "31743  [-0.4998133, 0.21075934, -0.1710357, 0.1950991...   \n",
       "31746  [-0.4232357, 0.27518612, -0.1223748, 0.1546501...   \n",
       "\n",
       "                                        answer_embedding  \n",
       "29531  [-0.12213257, 0.26806858, 0.04654521, 0.139121...  \n",
       "31743  [-0.2732135, -0.006451058, 0.19289777, 0.24179...  \n",
       "31746  [-0.12213257, 0.26806858, 0.04654521, 0.139121...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(training_df[training_df[\"question\"] == \"should i take some medicine to stop heavy bleeding after an i-pill?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(training_df.iloc[29531][\"question_embedding\"] == training_df.iloc[31743][\"question_embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should i take some medicine to stop heavy bleeding after an i-pill?\n"
     ]
    }
   ],
   "source": [
    "print(training_df.iloc[29531][\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
